{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Package\n",
    "\n",
    "```\n",
    "Create a Dataset resource.\n",
    "Train an AutoML tabular classification Model resource.\n",
    "Create an Endpoint resource.\n",
    "Deploys the Model resource to the Endpoint resource.\n",
    "Compile the KFP pipeline.\n",
    "Execute the KFP pipeline using Vertex AI Pipelines\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 kfp \\\n",
    "                                 google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Project ID, Region and Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../../.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"asia-southeast2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://{PROJECT_ID}-demo-dataset-3\"\n",
    "\n",
    "# ! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from google.cloud import aiplatform\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import (Artifact, ClassificationMetrics, Input, Metrics, Output,\n",
    "                     component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"automl-tabular-demo-dataset-3-training\"\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/demo-dataset-3\".format(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"db-dtypes\"]\n",
    ")\n",
    "def preprocess_dataset_in_bq(\n",
    "    project: str,\n",
    "    location: str, \n",
    "    dataset: str,\n",
    "    table: str,\n",
    ") -> NamedTuple(\"Outputs\", [(\"preprocess_result\", str)]):\n",
    "    from google.cloud import bigquery\n",
    "    client = bigquery.Client(project=project, location=location)\n",
    "    QUERY = f'''CREATE OR REPLACE TABLE `{dataset}.{table}_preprocessed` AS\n",
    "SELECT\n",
    "    *,\n",
    "    ML.LABEL_ENCODER(purpose, 7, 5) OVER () AS purpose_encoded,\n",
    "    CASE \n",
    "      WHEN fico < 580 THEN 1\n",
    "      WHEN fico <= 669 THEN 2\n",
    "      WHEN fico <= 739 THEN 3\n",
    "      WHEN fico <= 799 THEN 4\n",
    "      ELSE 5\n",
    "    END AS fico_encoded\n",
    "FROM\n",
    "    `{dataset}.{table}`;\n",
    "    \n",
    "ALTER TABLE `demo_dataset_3.loan_data_preprocessed` DROP COLUMN IF EXISTS purpose;\n",
    "ALTER TABLE `demo_dataset_3.loan_data_preprocessed` DROP COLUMN IF EXISTS fico;\n",
    "'''\n",
    "    try:\n",
    "        query_job = client.query(QUERY)\n",
    "        query_job.result()\n",
    "        preprocess_result = 'true'\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        preprocess_result = 'false'\n",
    "    return (preprocess_result, )\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    preprocess_dataset_in_bq, \"preprocess_dataset_in_bq.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"db-dtypes\", \"pandas\", \"pandas-gbq\", \"scikit-learn\"]\n",
    ")\n",
    "def smote_dataset_store_in_bq(\n",
    "    project: str,\n",
    "    location: str, \n",
    "    dataset: str,\n",
    "    table: str,\n",
    ") -> NamedTuple(\"Outputs\", [(\"preprocess_result\", str)]):\n",
    "    from google.cloud import bigquery\n",
    "    from sklearn.utils import resample\n",
    "    import pandas as pd\n",
    "    client = bigquery.Client(project=project, location=location)\n",
    "    QUERY = f'''SELECT * FROM `{dataset}.{table}`'''\n",
    "    try:\n",
    "        df = client.query(QUERY).to_dataframe()\n",
    "        df_majority = df[df['not_fully_paid']==0]\n",
    "        df_minority = df[df['not_fully_paid']==1]\n",
    "        \n",
    "        df_minority_upsampled = resample(df_minority, \n",
    "                                        replace=True,\n",
    "                                        n_samples=len(df_majority),  \n",
    "                                        random_state=123)\n",
    "        \n",
    "        df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "        df.to_gbq(if_exists='replace', project_id=project, destination_table=f'{dataset}.{table}')\n",
    "        preprocess_result = 'true'\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        preprocess_result = 'false'\n",
    "    return (preprocess_result, )\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    preprocess_dataset_in_bq, \"preprocess_dataset_in_bq.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-6:latest\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def classification_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    thresholds_dict_str: str,\n",
    "    model: Input[Artifact],\n",
    "    metrics: Output[Metrics],\n",
    "    metricsc: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "    \n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project)\n",
    "\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(model):\n",
    "        response = model.list_model_evaluations()\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            evaluation = evaluation.to_dict()\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation[\"name\"])\n",
    "            print(\" metrics_schema_uri:\", evaluation[\"metricsSchemaUri\"])\n",
    "            metrics = evaluation[\"metrics\"]\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "\n",
    "        return (\n",
    "            evaluation[\"name\"],\n",
    "            metrics_list,\n",
    "            metrics_string_list,\n",
    "        )\n",
    "\n",
    "    # Use the given metrics threshold(s) to determine whether the model is\n",
    "    # accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\"{} < {}; returning False\".format(metrics_dict[k], v))\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.metadata[\"resourceName\"]\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    # Get the trained model resource\n",
    "    model = aiplatform.Model(model_resource_path)\n",
    "\n",
    "    # Get model evaluation metrics from the the trained model\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(model)\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = classification_thresholds_check(metrics_list[0], thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "\n",
    "    return (dep_decision,)\n",
    "\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    classification_model_eval_metrics, \"tabular_eval_component.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=PIPELINE_NAME, pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    bq_source: str,\n",
    "    DATASET_DISPLAY_NAME: str,\n",
    "    TRAINING_DISPLAY_NAME: str,\n",
    "    MODEL_DISPLAY_NAME: str,\n",
    "    ENDPOINT_DISPLAY_NAME: str,\n",
    "    MACHINE_TYPE: str,\n",
    "    project: str,\n",
    "    gcp_region: str,\n",
    "    thresholds_dict_str: str,\n",
    "):\n",
    "    from google_cloud_pipeline_components.v1.automl.training_job import \\\n",
    "        AutoMLTabularTrainingJobRunOp\n",
    "    from google_cloud_pipeline_components.v1.dataset.create_tabular_dataset.component import \\\n",
    "        tabular_dataset_create as TabularDatasetCreateOp\n",
    "    from google_cloud_pipeline_components.v1.endpoint.create_endpoint.component import \\\n",
    "        endpoint_create as EndpointCreateOp\n",
    "    from google_cloud_pipeline_components.v1.endpoint.deploy_model.component import \\\n",
    "        model_deploy as ModelDeployOp\n",
    "\n",
    "    preprocess_dataset = preprocess_dataset_in_bq(\n",
    "        project=project,\n",
    "        location='asia-southeast2',\n",
    "        dataset='demo_dataset_3',\n",
    "        table='loan_data'\n",
    "    )\n",
    "    with dsl.If(\n",
    "        preprocess_dataset.outputs['preprocess_result'] == 'true',\n",
    "        name='clean_dataset_decision'\n",
    "    ):\n",
    "        smote_dataset = smote_dataset_store_in_bq(\n",
    "            project=project,\n",
    "            location='asia-southeast2',\n",
    "            dataset='demo_dataset_3',\n",
    "            table='loan_data_preprocessed'\n",
    "        )\n",
    "\n",
    "        with dsl.If(\n",
    "            smote_dataset.outputs['preprocess_result'] == 'true',\n",
    "            name='clean_dataset_decision'\n",
    "        ):\n",
    "\n",
    "            dataset_create_op = TabularDatasetCreateOp(\n",
    "                project=project,\n",
    "                location=gcp_region,\n",
    "                display_name=DATASET_DISPLAY_NAME,\n",
    "                bq_source=bq_source,\n",
    "            )\n",
    "\n",
    "            training_op = AutoMLTabularTrainingJobRunOp(\n",
    "                project=project,\n",
    "                location=gcp_region,\n",
    "                display_name=TRAINING_DISPLAY_NAME,\n",
    "                optimization_prediction_type=\"classification\",\n",
    "                optimization_objective=\"minimize-log-loss\",\n",
    "                budget_milli_node_hours=1000,\n",
    "                model_display_name=MODEL_DISPLAY_NAME,\n",
    "                column_specs={\n",
    "                    \"credit_policy\": \"categorical\",\n",
    "                    \"int_rate\": \"numeric\",\n",
    "                    \"installment\": \"numeric\",\n",
    "                    \"log_annual_inc\": \"numeric\",\n",
    "                    \"dti\": \"numeric\",\n",
    "                    \"fico_encoded\": \"numeric\",\n",
    "                    \"days_with_cr_line\": \"numeric\",\n",
    "                    \"revol_bal\": \"numeric\",\n",
    "                    \"revol_util\": \"numeric\",\n",
    "                    \"inq_last_6mths\": \"numeric\",\n",
    "                    \"delinq_2yrs\": \"numeric\",\n",
    "                    \"pub_rec\": \"numeric\",\n",
    "                    \"not_fully_paid\": \"numeric\",\n",
    "                    \"purpose_encoded\": \"numeric\",\n",
    "                },\n",
    "                dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "                target_column=\"not_fully_paid\",\n",
    "            )\n",
    "\n",
    "            model_eval_task = classification_model_eval_metrics(\n",
    "                project=project,\n",
    "                location=gcp_region,\n",
    "                thresholds_dict_str=thresholds_dict_str,\n",
    "                model=training_op.outputs[\"model\"],\n",
    "            )\n",
    "\n",
    "            with dsl.If(\n",
    "                model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "                name=\"deploy_decision\",\n",
    "            ):\n",
    "\n",
    "                endpoint_op = EndpointCreateOp(\n",
    "                    project=project,\n",
    "                    location=gcp_region,\n",
    "                    display_name=ENDPOINT_DISPLAY_NAME,\n",
    "                )\n",
    "\n",
    "                ModelDeployOp(\n",
    "                    model=training_op.outputs[\"model\"],\n",
    "                    endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "                    dedicated_resources_min_replica_count=1,\n",
    "                    dedicated_resources_max_replica_count=1,\n",
    "                    dedicated_resources_machine_type=MACHINE_TYPE,\n",
    "                )\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"tabular_classification_pipeline.yaml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the display-names for Vertex AI resources\n",
    "PIPELINE_DISPLAY_NAME = \"demo-dataset-3-loan-data-pipeline\"  # @param {type:\"string\"}\n",
    "DATASET_DISPLAY_NAME = \"demo-dataset-3-loan-data-dataset\"  # @param {type:\"string\"}\n",
    "MODEL_DISPLAY_NAME = \"demo-dataset-3-loan-data-model\"  # @param {type:\"string\"}\n",
    "TRAINING_DISPLAY_NAME = \"demo-dataset-3-loan-data-training\"  # @param {type:\"string\"}\n",
    "ENDPOINT_DISPLAY_NAME = \"demo-dataset-3-loan-data-endpoint\"  # @param {type:\"string\"}\n",
    "\n",
    "# Otherwise, use the default display-names\n",
    "if PIPELINE_DISPLAY_NAME == \"demo-dataset-3-loan-data-pipeline\":\n",
    "    PIPELINE_DISPLAY_NAME = f\"pipeline_demo3_{UUID}\"\n",
    "\n",
    "if DATASET_DISPLAY_NAME == \"demo-dataset-3-loan-data-dataset\":\n",
    "    DATASET_DISPLAY_NAME = f\"dataset_demo3_{UUID}\"\n",
    "\n",
    "if MODEL_DISPLAY_NAME == \"demo-dataset-3-loan-data-model\":\n",
    "    MODEL_DISPLAY_NAME = f\"model_demo3_{UUID}\"\n",
    "\n",
    "if TRAINING_DISPLAY_NAME == \"demo-dataset-3-loan-data-training\":\n",
    "    TRAINING_DISPLAY_NAME = f\"automl_training_demo3_{UUID}\"\n",
    "\n",
    "if ENDPOINT_DISPLAY_NAME == \"demo-dataset-3-loan-data-endpoint\":\n",
    "    ENDPOINT_DISPLAY_NAME = f\"endpoint_demo3_{UUID}\"\n",
    "\n",
    "# Set machine type\n",
    "MACHINE_TYPE = \"n1-standard-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate region of the given source (BigQuery) against region of the pipeline\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '...'\n",
    "\n",
    "bq_source = \"dla-ml-specialization.demo_dataset_3.loan_data_preprocessed\"\n",
    "\n",
    "client = bigquery.Client()\n",
    "bq_region = client.get_table(bq_source).location.lower()\n",
    "try:\n",
    "    assert bq_region in REGION\n",
    "    print(f\"Region validated: {REGION}\")\n",
    "except AssertionError:\n",
    "    print(\n",
    "        \"Please make sure the region of BigQuery (source) and that of the pipeline are the same.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the pipeline\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=PIPELINE_DISPLAY_NAME,\n",
    "    template_path=\"tabular_classification_pipeline.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        \"project\": PROJECT_ID,\n",
    "        \"gcp_region\": REGION,\n",
    "        \"bq_source\": f\"bq://{bq_source}\",\n",
    "        \"thresholds_dict_str\": '{\"auRoc\": 0.80}',\n",
    "        \"DATASET_DISPLAY_NAME\": DATASET_DISPLAY_NAME,\n",
    "        \"TRAINING_DISPLAY_NAME\": TRAINING_DISPLAY_NAME,\n",
    "        \"MODEL_DISPLAY_NAME\": MODEL_DISPLAY_NAME,\n",
    "        \"ENDPOINT_DISPLAY_NAME\": ENDPOINT_DISPLAY_NAME,\n",
    "        \"MACHINE_TYPE\": MACHINE_TYPE,\n",
    "    },\n",
    "    enable_caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the job\n",
    "job.run(service_account='...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_df = aiplatform.get_pipeline_df(pipeline=PIPELINE_NAME)\n",
    "print(pipeline_df.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
